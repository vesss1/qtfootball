# Football Analysis Project

## Introduction
The goal of this project is to detect and track players, referees, and footballs in a video using YOLO, one of the best AI object detection models available. We will also train the model to improve its performance. Additionally, we will assign players to teams based on the colors of their t-shirts using Kmeans for pixel segmentation and clustering. With this information, we can measure a team's ball acquisition percentage in a match. We will also use optical flow to measure camera movement between frames, enabling us to accurately measure a player's movement. Furthermore, we will implement perspective transformation to represent the scene's depth and perspective, allowing us to measure a player's movement in meters rather than pixels. Finally, we will calculate a player's speed and the distance covered. This project covers various concepts and addresses real-world problems, making it suitable for both beginners and experienced machine learning engineers.

![Screenshot](output_videos/screenshot.png)

## Features
- **Object Detection & Tracking**: Detect and track players, referees, and ball using YOLO
- **Team Assignment**: Automatic team identification using K-means clustering
- **Ball Possession Analysis**: Track which team has the ball
- **Camera Movement Compensation**: Account for camera panning and movement
- **Speed & Distance Metrics**: Calculate player speed (km/h) and distance (m)
- **üÜï Data Export**: Extract all analysis data to JSON/CSV formats for further analysis

## Data Export Feature
All information displayed on the output video can now be **extracted and saved** as structured data:
- Player tracking data (position, speed, distance, team)
- Ball tracking and possession
- Team ball control statistics
- Camera movement data
- Frame-by-frame analysis

**Export formats**: JSON (complete data) and CSV (tabular data)

üìñ See [DATA_EXPORT_README.md](DATA_EXPORT_README.md) for detailed documentation.

## Player Numbers in Output Video

The numbers displayed above each player in the output video are **Track IDs** automatically generated by the ByteTrack tracking algorithm. These are NOT jersey numbers.

### Key Points:
- **Track IDs** are unique identifiers assigned to each detected player
- Numbers are generated automatically by the **ByteTrack** algorithm
- IDs remain consistent while a player is continuously tracked
- If tracking is lost (e.g., player leaves frame), a new ID may be assigned upon re-detection
- Track IDs are used in exported data files to identify players

üìñ See [PLAYER_NUMBERS_EXPLAINED_ÁêÉÂì°ËôüÁ¢ºË™™Êòé.md](PLAYER_NUMBERS_EXPLAINED_ÁêÉÂì°ËôüÁ¢ºË™™Êòé.md) for detailed explanation in both English and Chinese.

## Modules Used
The following modules are used in this project:
- YOLO: AI object detection model
- ByteTrack: Multi-object tracking algorithm (assigns player numbers/track IDs)
- Kmeans: Pixel segmentation and clustering to detect t-shirt color
- Optical Flow: Measure camera movement
- Perspective Transformation: Represent scene depth and perspective
- Speed and distance calculation per player

## Trained Models
- [Trained Yolo v5](https://drive.google.com/file/d/1DC2kCygbBWUKheQ_9cFziCsYVSRw6axK/view?usp=sharing)

## Sample video
-  [Sample input video](https://drive.google.com/file/d/1t6agoqggZKx6thamUuPAIdN_1zR9v9S_/view?usp=sharing)

## Requirements
To run this project, you need to have the following requirements installed:
- Python 3.x
- ultralytics
- supervision
- OpenCV
- NumPy
- Matplotlib
- Pandas